{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c570d60e",
   "metadata": {},
   "source": [
    "# Project Name: Student Success Chatbot\n",
    "\n",
    "## Project Synopsis\n",
    "\n",
    "Student Success Advisors (SSAs) are currently overwhelmed by low-complexity, high-volume inquiries. A reduction in SSA staffing highlights the urgent need for a scalable solution. This project proposes the design and implementation of a chatbot-based self-service tool to handle frequently asked questions (FAQs), integrated with a fallback mechanism (\"off-ramp\") to escalate complex queries to human advisors.\n",
    "\n",
    "## Team member names\n",
    "\n",
    "1. Yu Chen Chou \n",
    "2. Zhimin Xiong \n",
    "3. Haysam Elamin\n",
    "\n",
    "## Data Source\n",
    "* kb1.csv: Content from the College website.\n",
    "* kb2.csv: Content from the Student Success Portal website.\n",
    "* kb2.csv: Content from Student_Fees_FQA_Winter_2024.pdf and RO_FQA_Winter_2024.pdf.\n",
    "* student_queries.csv: synthetic dataset to train the intent classifier model.\n",
    "* GoEmotions dataset from Hugging Face ü§ó Datasets library.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In order to run the app, follow the steps as below:\n",
    "* Create a Virtual Environment using Python 3.10 or 3.9.6, and restore requirements.txt\n",
    "* Create a .env file with OPENAI_API_KEY\n",
    "* Models for emotion classifier and intent classifier are too big to push to GitHub.\n",
    "    * run notebooks\\emotionModelTrainer.ipynb to train and save the emotion classifier model\n",
    "    * run notebooks\\intentModelTrainer.ipynb to train and save the intent classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1c13b",
   "metadata": {},
   "source": [
    "## Streamlit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "from datetime import datetime\n",
    "\n",
    "from src.chatbotController import ChatbotController\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(page_title=\"Conestoga Student Support Chatbot\", page_icon=\"ü§ñ\")\n",
    "\n",
    "# Hide Streamlit footer\n",
    "st.markdown(\"<style>footer {visibility: hidden;}</style>\", unsafe_allow_html=True)\n",
    "\n",
    "# Custom CSS to make layout responsive\n",
    "# Custom CSS\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .chat-input {\n",
    "            border-top: 1px solid #eee !important;\n",
    "            padding-top: 10px;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"üìö Student Support Chatbot\")\n",
    "\n",
    "# Initialize chatbot\n",
    "if \"chatbot\" not in st.session_state:\n",
    "    st.session_state.chatbot = ChatbotController()\n",
    "    st.session_state.chatbot.get_answer(\"hello\")\n",
    "\n",
    "# Initialize history\n",
    "if \"history\" not in st.session_state:\n",
    "    st.session_state.history = [{\n",
    "                \"sender\": \"Lulu\",\n",
    "                \"role\": \"Student Success Advisor\",\n",
    "                \"avatar\": \"üíÅ‚Äç‚ôÄÔ∏è\",\n",
    "                \"text\": \"Hello, my name is Lulu, how can I help you today?\",\n",
    "                \"time\": datetime.now().strftime(\"%H:%M\")\n",
    "            }]\n",
    "\n",
    "# If input was previously stored, clear it before rendering the input box\n",
    "if \"clear_input\" in st.session_state:\n",
    "    st.session_state.chat_input = \"\"\n",
    "    del st.session_state[\"clear_input\"]\n",
    "\n",
    "# --- Build the chat history HTML ---\n",
    "chat_body = \"\"\n",
    "\n",
    "for msg in st.session_state.history:\n",
    "    if msg.get(\"sender\") == \"System\":\n",
    "        chat_body += f\"<div style='text-align:center; color: gray; font-size: 12px; margin: 10px 0;'>{msg['text']}</div>\"\n",
    "    else:\n",
    "        align = \"left\" if msg[\"sender\"] != \"You\" else \"right\"\n",
    "        bubble_color = \"#daf4fa\"\n",
    "        avatar = msg.get(\"avatar\", \"üë§\")\n",
    "        chat_body += f\"<div style='display:flex; flex-direction:{'row' if align == 'left' else 'row-reverse'}; margin-bottom:10px;'><div style='font-size:24px; margin:0 10px;'>{avatar}</div><div><div style='font-weight:bold; font-size:13px;color:lightgray;'>{msg['sender']}</div><div style='font-size:11px; color:gray;'>{msg.get('role', '')}</div><div style='background-color:{bubble_color}; color:black; padding:10px; border-radius:10px; max-width:600px; margin-top:4px;'>{msg['text']}</div></div></div>\"\n",
    "\n",
    "# Scroll to bottom using JavaScript\n",
    "full_html = f\"<div id='chat-box' style='height: 400px; overflow-y: auto; border: 1px solid #ccc; padding-right: 10px; border-radius: 10px;'>{chat_body}</div><script>var chatBox = document.getElementById('chat-box'); if (chatBox) {{ chatBox.scrollTop = chatBox.scrollHeight; }}</script>\"\n",
    "\n",
    "# Render using components.html (not st.markdown)\n",
    "components.html(full_html, height=400)\n",
    "\n",
    "# Show \"Advisor is typing...\" message if a response is pending\n",
    "if \"pending_input\" in st.session_state:\n",
    "    st.markdown(\n",
    "        \"<div style='color: gray; font-style: italic; padding: 5px 0;'>üíÅ‚Äç‚ôÄÔ∏è Lulu is typing ...</div>\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "# --- Chat input ---\n",
    "st.markdown(\"<div class='chat-input'>\", unsafe_allow_html=True)\n",
    "user_input = st.text_input(\"Type a message here and press Enter...\", label_visibility=\"collapsed\", key=\"chat_input\")\n",
    "\n",
    "if \"pending_input\" in st.session_state:\n",
    "    user_input = st.session_state.pop(\"pending_input\")  # Remove to avoid reprocessing\n",
    "    reply = st.session_state.chatbot.get_answer(user_input)\n",
    "\n",
    "    st.session_state.history.append({\n",
    "        \"sender\": \"Lulu\",\n",
    "        \"role\": \"Student Success Advisor\",\n",
    "        \"avatar\": \"üíÅ‚Äç‚ôÄÔ∏è\",\n",
    "        \"text\": reply,\n",
    "        \"time\": datetime.now().strftime(\"%H:%M\")\n",
    "    })\n",
    "    st.rerun()\n",
    "\n",
    "if user_input:\n",
    "    st.session_state.history.append({\n",
    "        \"sender\": \"You\",\n",
    "        \"avatar\": \"üßë‚Äçüéì\",\n",
    "        \"text\": user_input,\n",
    "        \"time\": datetime.now().strftime(\"%H:%M\")\n",
    "    })\n",
    "\n",
    "    # Store input to handle bot reply on next run\n",
    "    st.session_state[\"pending_input\"] = user_input\n",
    "    st.session_state[\"clear_input\"] = True  \n",
    "    st.rerun()\n",
    "\n",
    "st.markdown(\"</div>\", unsafe_allow_html=True)  # Close chat-input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b4916",
   "metadata": {},
   "source": [
    "## Chatbot Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e941afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.handlers.answerGenerator import AnswerGenerator\n",
    "from src.handlers.emotionClassifier import EmotionClassifier\n",
    "from src.handlers.intentClassifier import IntentClassifier\n",
    "from src.handlers.interactionLogger import InteractionLogger\n",
    "from src.handlers.searchEngine import FaissSearchEngine\n",
    "import concurrent.futures\n",
    "\n",
    "class ChatbotController:\n",
    "    \"\"\"\n",
    "    ChatbotController orchestrates the main components of the student-facing chatbot system.\n",
    "    \n",
    "    It integrates intent classification, emotion detection, vector-based knowledge retrieval,\n",
    "    answer generation, and interaction logging. The controller processes incoming student queries\n",
    "    by identifying their intent and emotional state in parallel. If distress is detected, it\n",
    "    responds with a referral to a human advisor. Otherwise, it retrieves relevant context from the\n",
    "    knowledge base and generates a user-friendly answer using a language model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.intentClassifier = IntentClassifier()\n",
    "        self.emotionClassifier = EmotionClassifier()\n",
    "        self.answer_generator = AnswerGenerator()\n",
    "        self.vector_search = FaissSearchEngine()\n",
    "        self.logger = InteractionLogger()\n",
    "\n",
    "    def get_knowledge_base(self, query):\n",
    "        kbResults = self.vector_search.search(query, top_k=10)\n",
    "        # Combine top-k chunks into a single context string\n",
    "        context = \"\\n\\n\".join([f\"{chunk['content']}\" for chunk, _ in kbResults])\n",
    "        if len(context) > 10000:\n",
    "            context = context[:10000]\n",
    "        return context\n",
    "\n",
    "    def get_answer(self, query):\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            emotionPrediction = executor.submit(self.emotionClassifier.predict, query)\n",
    "            intentPrediction = executor.submit(self.intentClassifier.predict, query)\n",
    "\n",
    "            emotion = emotionPrediction.result()\n",
    "            intent = intentPrediction.result()\n",
    "\n",
    "        # escalate to human agent\n",
    "        if (emotion is not None and emotion in [\"anger\", \"sadness\", \"fear\", \"disgust\"]):\n",
    "            # log\n",
    "            self.logger.log('student_123',query,intent,emotion,\"\")\n",
    "            return \"I'm really sorry you're feeling this way. You don‚Äôt have to go through it alone. Please speak with a Student Success Advisor who can support you. You can book an appointment at <a href='https://collegeportal.edu/ssa-booking'>https://collegeportal.edu/ssa-booking</a> or call us directly at 555-123-4567.\"\n",
    "        # get context from knowledge base\n",
    "        context = self.get_knowledge_base(query)\n",
    "        # Generate answer\n",
    "        answer = self.answer_generator.generate_answer_with_openai(context, query)\n",
    "        # log\n",
    "        self.logger.log('student_123',query,intent,emotion, answer)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb79e7",
   "metadata": {},
   "source": [
    "## Intent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47618af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "class IntentClassifier():\n",
    "    \"\"\"\n",
    "    Classifies the intent behind a student's query using a fine-tuned BERT model.\n",
    "\n",
    "    This class loads a pre-trained intent classification model and predicts the most \n",
    "    likely intent category from a predefined list of student-related intents such as \n",
    "    course information or enrollment.\n",
    "\n",
    "    Methods:\n",
    "        predict(text):\n",
    "            Returns the predicted intent label for the given text input.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path=\"models/intentClassifier\"):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.eval()\n",
    "        self.labels = [\n",
    "            \"Course Information\",\n",
    "            \"Enrollment / Course Registration\",\n",
    "            \"Withdrawal or Drop Course\",\n",
    "            \"Access Issues (portal/login)\",\n",
    "            \"Technical Support\",\n",
    "            \"Tuition/Fees Inquiry\",\n",
    "            \"Scholarship/Financial Aid\",\n",
    "            \"Mental Health Concerns\",\n",
    "            \"Stress or Burnout\",\n",
    "            \"Bullying or Harassment\",\n",
    "            \"Administrative Support\",\n",
    "            \"Campus Facilities\",\n",
    "            \"Housing/Accommodation\",\n",
    "            \"Extracurricular Activities\",\n",
    "            \"General Complaint\"\n",
    "        ]\n",
    "\n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            predicted_class_id = outputs.logits.argmax().item()\n",
    "        return self.labels[predicted_class_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59852ea",
   "metadata": {},
   "source": [
    "## Emotion Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EmotionClassifier:\n",
    "    \"\"\"\n",
    "    Classifies emotional tone in a given text using a fine-tuned BERT model.\n",
    "\n",
    "    This class loads a pre-trained emotion classification model (fine-tuned on a subset of \n",
    "    negative emotions) and predicts the most probable emotion label from a fixed list, \n",
    "    if the confidence exceeds a specified threshold.\n",
    "\n",
    "    Methods:\n",
    "        predict(text, threshold=0.9):\n",
    "            Returns the predicted emotion label if the model's confidence exceeds the threshold;\n",
    "            otherwise, returns None.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path=\"models/emotionClassifier\"):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.eval()\n",
    "        self.labels: list = [\"sadness\", \"grief\", \"fear\", \"remorse\", \"disappointment\", \"nervousness\", \"embarrassment\"]\n",
    "\n",
    "    def predict(self, text, threshold=0.85):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        for label, prob in zip(self.labels, probs):\n",
    "            if prob >= threshold:\n",
    "                return label\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177caf7",
   "metadata": {},
   "source": [
    "## Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class FaissSearchEngine:\n",
    "    \"\"\"\n",
    "    Provides semantic search functionality over a pre-built FAISS index of text chunks.\n",
    "\n",
    "    This class loads a FAISS index and its associated metadata, and uses a sentence embedding \n",
    "    model (MiniLM) to perform efficient vector-based similarity search. Duplicate content is \n",
    "    filtered to ensure diverse results.\n",
    "\n",
    "    Methods:\n",
    "        search(query: str, top_k: int = 5) -> List[Tuple[Dict, float]]:\n",
    "            Returns top-k semantically relevant results for a given query, excluding duplicates.\n",
    "    \"\"\"\n",
    "    def __init__(self, index_path='models/faiss.index', meta_path='models/texts.pkl'):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.index = None\n",
    "        self.texts = None\n",
    "        self._load_index(index_path, meta_path)\n",
    "\n",
    "    def _load_index(self, index_path, meta_path):\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        with open(meta_path, 'rb') as f:\n",
    "            self.texts = pickle.load(f)\n",
    "\n",
    "    def search(self, query, top_k=5):\n",
    "        query_embedding = self.model.encode([query])\n",
    "        query_embedding = np.array(query_embedding).astype('float32')\n",
    "        D, I = self.index.search(query_embedding, top_k * 2)\n",
    "        seen = set()\n",
    "        results = []\n",
    "        for rank, i in enumerate(I[0]):\n",
    "            item = self.texts[i]\n",
    "            content = item['content']\n",
    "            if content not in seen:\n",
    "                seen.add(content)\n",
    "                results.append((item, D[0][rank]))\n",
    "            if len(results) == top_k:\n",
    "                break\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb1ca58",
   "metadata": {},
   "source": [
    "## Answer Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "class AnswerGenerator:\n",
    "    \"\"\"\n",
    "    Generates natural language answers to student queries using large language models (LLMs).\n",
    "\n",
    "    This class supports integration with OpenAI (e.g., GPT-4) to provide student support responses \n",
    "    based on retrieved knowledge base context.\n",
    "\n",
    "    The answers are generated in the role of a student success advisor, with a consistent prompt \n",
    "    guiding the model to use provided context and gracefully handle unknowns.\n",
    "\n",
    "    Methods:\n",
    "        generate_answer_with_openai(context, question, model):\n",
    "            Uses OpenAI's ChatCompletion API to generate a response based on the given context and question.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def generate_answer_with_openai(self, context: str, question: str, model: str = \"gpt-4\") -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful student success adivor. Use the provided context to answer the student's question. If the answer is not in the context, answer it with the best of your knowledge.'\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739089c1",
   "metadata": {},
   "source": [
    "## Interation Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b24d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "class InteractionLogger:\n",
    "    \"\"\"\n",
    "    Logs chatbot interactions to a CSV file for record-keeping and analysis.\n",
    "\n",
    "    This class handles the creation and maintenance of a log file that records \n",
    "    student interactions with the chatbot, including timestamp, student ID, \n",
    "    question, predicted intent, and detected emotion.\n",
    "\n",
    "    Methods:\n",
    "        log(student, question, intent, emotion):\n",
    "            Appends a new interaction entry to the log file with the current timestamp.\n",
    "    \"\"\"\n",
    "    def __init__(self, log_file='logs/log.csv'):\n",
    "        self.log_file = log_file\n",
    "        # Create the file with headers if it doesn't exist\n",
    "        if not os.path.exists(self.log_file):\n",
    "            with open(self.log_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['datetime', 'student', 'question', 'intent', 'emotion', 'answer'])\n",
    "\n",
    "    def log(self, student, question, intent, emotion, answer):\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        with open(self.log_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([now, student, question, intent, emotion, answer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977b73d",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distressed_emotions = [\"anger\", \"sadness\", \"fear\", \"disgust\"]\n",
    "# Load log CSV file\n",
    "df = pd.read_csv('logs/log.csv', parse_dates=['datetime'])\n",
    "df[\"is_distressed\"] = df['emotion'].isin(distressed_emotions)\n",
    "st.title(\"üìä Chatbot Dashboard\")\n",
    "\n",
    "# Intent type distribution map\n",
    "st.header(\"‚ú® FAQ Intent Type Distribution\")\n",
    "intent_counts = df['intent'].value_counts()\n",
    "# Sort values\n",
    "intent_counts = intent_counts.sort_values(ascending=False)\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x=intent_counts.values, y=intent_counts.index, ax=ax, palette='Blues_d')\n",
    "# Labels and title\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Intent Type')\n",
    "ax.set_title('Intent Type Distribution')\n",
    "# Layout and display\n",
    "plt.tight_layout()\n",
    "st.pyplot(fig)\n",
    "\n",
    "# Percentage of troublesome messages\n",
    "st.header(\"‚ö†Ô∏è Percentage of Disturbing Messages\")\n",
    "distress_counts = df['is_distressed'].value_counts().rename({True: 'Distressed', False: 'Not Distressed'})\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "ax2.bar(distress_counts.index, distress_counts.values, color=['red', 'green'])\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Distress Message Proportion')\n",
    "st.pyplot(fig2)\n",
    "\n",
    "# Heat map of troublesome messages\n",
    "st.header(\"üìÜ Daily Distress Information Heatmap\")\n",
    "df['date'] = df['datetime'].dt.date\n",
    "pivot = df.pivot_table(index='date', columns='is_distressed', values='student', aggfunc='count', fill_value=0)\n",
    "pivot.rename(columns={False: 'Not Distressed', True: 'Distressed'}, inplace=True)\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(pivot, annot=True, fmt=\"d\", cmap='YlOrRd', ax=ax3)\n",
    "ax3.set_title('Daily Distress Messages Heatmap')\n",
    "st.pyplot(fig3)\n",
    "\n",
    "# Latest trouble information list\n",
    "st.header(\"üö® Latest Troubling Messages\")\n",
    "distressed = df[df['is_distressed']]\n",
    "st.dataframe(distressed[['datetime', 'student', 'question', 'intent']].sort_values('datetime', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd191e",
   "metadata": {},
   "source": [
    "## Vector Index Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237340b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "class VectorIndexBuilder:\n",
    "    \"\"\"\n",
    "    Builds and saves a FAISS vector index from CSV files containing text chunks.\n",
    "\n",
    "    This class uses the SentenceTransformer model ('all-MiniLM-L6-v2') to generate \n",
    "    dense vector embeddings for textual content extracted from CSV files in data folder.\n",
    "    Each CSV is expected to contain 'url', 'chunk_number', and 'content' columns and has name like kb*.csv.\n",
    "\n",
    "    The resulting embeddings are indexed using FAISS (IndexFlatL2), enabling efficient\n",
    "    vector-based semantic search. Both the FAISS index and associated metadata (text and source info)\n",
    "    are saved to disk for later retrieval and use.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.index = None\n",
    "        self.texts = []\n",
    "    \n",
    "    def build_index_from_folder(self, folder_path):\n",
    "        csv_files = glob(os.path.join(folder_path, \"kb*.csv\"))\n",
    "        all_texts = []\n",
    "        all_records = []\n",
    "\n",
    "        for path in csv_files:\n",
    "            df = pd.read_csv(path)\n",
    "            if {'url', 'chunk_number', 'content'}.issubset(df.columns):\n",
    "                df = df.fillna('')  # Ensure no NaNs\n",
    "                all_texts.extend(df['content'].astype(str).tolist())\n",
    "                all_records.extend(df[['url', 'chunk_number', 'content']].to_dict(orient='records'))\n",
    "\n",
    "        self.texts = all_records  # Store metadata for each chunk\n",
    "        embeddings = self.model.encode(all_texts, show_progress_bar=True)\n",
    "        embeddings = np.array(embeddings).astype('float32')  # FAISS needs float32\n",
    "        self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    def save_index(self, index_path='models/faiss.index', meta_path='models/texts.pkl'):\n",
    "        faiss.write_index(self.index, index_path)\n",
    "        with open(meta_path, 'wb') as f:\n",
    "            pickle.dump(self.texts, f)\n",
    "\n",
    "builder = VectorIndexBuilder()\n",
    "builder.build_index_from_folder(\"data\")\n",
    "builder.save_index()\n",
    "print(\"‚úÖ Index and metadata saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1ea12",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
